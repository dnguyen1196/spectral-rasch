{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import girth\n",
    "from girth import rasch_conditional\n",
    "from irt.data.rasch import generate_data, generate_data_positive_scores\n",
    "from irt.algorithms.spectral_estimator import spectral_estimate\n",
    "from irt.algorithms import spectral_estimator\n",
    "from irt.algorithms import conditional_mle, joint_mle\n",
    "from irt.algorithms import rasch_mml\n",
    "from irt.algorithms import eigen_vector_method\n",
    "from irt.evaluation import eval_utils\n",
    "\n",
    "# import data (you supply this function)\n",
    "from scipy.stats import norm\n",
    "# my_data = import_data(filename)\n",
    "\n",
    "# # Assume its dichotomous data with True -> 1 and False -> 0\n",
    "# tagged_data = tag_missing_data(my_data, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_betas_error(beta, betah):\n",
    "    assert(len(beta) == len(betah))\n",
    "    beta_norm = beta - np.mean(beta)\n",
    "    betah_norm = betah - np.mean(betah)\n",
    "    return np.linalg.norm(beta_norm - betah_norm)\n",
    "\n",
    "def relative_z_error(z, zh):\n",
    "    return np.linalg.norm(z - zh)/np.linalg.norm(z)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=100, m=20, ASE=1.8897741757630346 (0.0035391688346862794), CMLE=nan (nan), MMLE=nan (nan), Choppin=nan (nan), Pair=nan (nan), Saaty=1.4808395095169322 (0.31213884353637694)\n",
      "n=200, m=20, ASE=1.2375338556542836 (0.006629884243011475), CMLE=nan (nan), MMLE=nan (nan), Choppin=nan (nan), Pair=nan (nan), Saaty=0.9917606038985861 (0.3644156098365784)\n",
      "n=500, m=20, ASE=0.752267319467532 (0.006219041347503662), CMLE=nan (nan), MMLE=nan (nan), Choppin=nan (nan), Pair=nan (nan), Saaty=0.6085449201047346 (0.3702566146850586)\n",
      "n=1000, m=20, ASE=0.524908851340695 (0.013058972358703614), CMLE=nan (nan), MMLE=nan (nan), Choppin=nan (nan), Pair=nan (nan), Saaty=0.44320500225428416 (0.4627893567085266)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "errors_arr = []\n",
    "errors_ase_arr = []\n",
    "errors_cmle_arr = []\n",
    "errors_mmle_arr = []\n",
    "errors_choppin_arr = []\n",
    "errors_garner_arr = []\n",
    "errors_saaty_arr = []\n",
    "errors_pair_arr = []\n",
    "\n",
    "time_arr = []\n",
    "time_ase_arr = []\n",
    "time_cmle_arr = []\n",
    "time_mmle_arr = []\n",
    "time_choppin_arr = []\n",
    "time_garner_arr = []\n",
    "time_saaty_arr = []\n",
    "time_pair_arr = []\n",
    "\n",
    "n_array = [100, 200, 500, 1000] #, 2500, 5000]\n",
    "n_trials = 20\n",
    "m = 20\n",
    "\n",
    "expected_num_problems = 5\n",
    "\n",
    "p = expected_num_problems/m\n",
    "p = 1.0\n",
    "test_var = 2\n",
    "betas = np.random.normal(0, test_var, size=(m,))\n",
    "student_var = 3\n",
    "\n",
    "for n in n_array:\n",
    "    # w_students = np.ones((n,))\n",
    "    # p = np.sqrt(np.log(m)/n)\n",
    "    thetas = np.random.normal(0, student_var, size=(n,))\n",
    "\n",
    "    error_ase = []\n",
    "    error_cmle = []\n",
    "    error_mmle = []\n",
    "    error_choppin = []\n",
    "    error_garner = []\n",
    "    error_saaty = []\n",
    "    error_pair = []\n",
    "    \n",
    "    time_ase = []\n",
    "    time_cmle = []\n",
    "    time_mmle = []\n",
    "    time_garner = []\n",
    "    time_choppin = []\n",
    "    time_saaty = []\n",
    "    time_pair = []\n",
    "    \n",
    "    auc_mmle = []\n",
    "    auc_ase = []\n",
    "    \n",
    "    for _ in range(n_trials):\n",
    "        # Generate data\n",
    "        data = generate_data(betas, thetas, p)\n",
    "\n",
    "        # Accelerated spectral method\n",
    "        start = time.time()\n",
    "        lambd = 1./(m * np.log(m))\n",
    "        est_ase = spectral_estimate(data, lambd=lambd, regularization=\"uniform\")\n",
    "        time_ase += [(time.time() - start)]\n",
    "        error_ase += [relative_betas_error(betas, est_ase)]\n",
    "        \n",
    "        \n",
    "        # CMLE\n",
    "        \n",
    "        # Choppin method\n",
    "#         start = time.time()\n",
    "#         # est_choppin = eigen_vector_method.choppin_method(data, return_beta=True)\n",
    "#         # est_choppin = rasch_conditional(data)[\"Difficulty\"]\n",
    "#         est_choppin = conditional_mle.rasch_conditional_modified(data)\n",
    "#         # print(est_choppin)\n",
    "        \n",
    "#         time_choppin += [(time.time() - start)]\n",
    "#         error_choppin += [relative_betas_error(betas, est_choppin)]\n",
    "                \n",
    "        # Saaty's method\n",
    "        start = time.time()\n",
    "        # est_saaty = eigen_vector_method.saaty_method(data, return_beta=True)\n",
    "        est_saaty = conditional_mle.rasch_conditional_original(data, max_iters=1000000, return_beta=True)\n",
    "        time_saaty += [(time.time() - start)]\n",
    "        error_saaty += [relative_betas_error(betas, est_saaty)]\n",
    "        \n",
    "        # Pairwise method\n",
    "        # start = time.time()\n",
    "        # est_pair = eigen_vector_method.conditional_pairwise(data, 0.1)\n",
    "        # time_pair += [(time.time() - start)]\n",
    "        # error_pair += [relative_betas_error(betas, est_pair)]        \n",
    "\n",
    "    errors_ase_arr.append(error_ase)\n",
    "    errors_cmle_arr.append(error_cmle)\n",
    "    errors_mmle_arr.append(error_mmle)\n",
    "    errors_choppin_arr.append(error_choppin)\n",
    "    errors_garner_arr.append(error_garner)\n",
    "    errors_saaty_arr.append(error_saaty)\n",
    "    \n",
    "    time_ase_arr.append(time_ase)\n",
    "    time_cmle_arr.append(time_cmle)\n",
    "    time_mmle_arr.append(time_mmle)\n",
    "    time_choppin_arr.append(time_choppin)\n",
    "    time_garner_arr.append(time_garner)\n",
    "    time_saaty_arr.append(time_saaty)\n",
    "    \n",
    "    print(f\"n={n}, m={m}, ASE={np.nanmean(error_ase)} ({np.nanmean(time_ase)}), CMLE={np.nanmean(error_cmle)} ({np.nanmean(time_cmle)}), MMLE={np.nanmean(error_mmle)} ({np.nanmean(time_mmle)}), \" +\n",
    "          f\"Choppin={np.nanmean(error_choppin)} ({np.nanmean(time_choppin)}), Pair={np.nanmean(error_pair)} ({np.nanmean(time_pair)}), Saaty={np.nanmean(error_saaty)} ({np.nanmean(time_saaty)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.random.normal(0, 1, size=(10,))\n",
    "thetas = np.random.normal(0, 1, size=(200,))\n",
    "p = 0.5\n",
    "data = generate_data(betas, thetas, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15495205 -0.00724269 -1.29153982  0.72369513  0.46503433 -0.19279702\n",
      " -0.34724883  1.14108768 -0.51003487  0.17399814] 19.633915901184082\n",
      "2.0150779748321432\n",
      "[-0.15495049 -0.00724312 -1.29153977  0.7236956   0.4650336  -0.19279625\n",
      " -0.34724836  1.14108791 -0.51003592  0.17399678] 0.19191932678222656\n",
      "2.0150779109535395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "est_cmle = conditional_mle.rasch_conditional_modified(data, verbose=False)\n",
    "print(est_cmle, time.time() - start)\n",
    "print(relative_betas_error(est_cmle, betas))\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# est_cmle = conditional_mle.rasch_conditional_gradient(data, verbose=False)\n",
    "# print(est_cmle, time.time() - start)\n",
    "# print(relative_betas_error(est_cmle, betas))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "est_cmle_og = conditional_mle.rasch_conditional_original(data, max_iters=int(1e6), verbose=False)\n",
    "print(est_cmle_og, time.time() - start)\n",
    "print(relative_betas_error(est_cmle_og, betas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc04afc9-0ba4-412e-9c9d-3be3bc415abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e5065d-1ea8-4d1f-a24b-5f06aaa00a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from irt.evaluation import eval_utils\n",
    "from irt.data import data_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import girth\n",
    "# from girth import rasch_conditional\n",
    "from irt.data.rasch import generate_data\n",
    "from irt.algorithms.spectral_estimator import spectral_estimate, construct_markov_chain, construct_markov_chain_accelerated\n",
    "from irt.algorithms import conditional_mle\n",
    "from irt.algorithms import rasch_mml\n",
    "from irt.evaluation.eval_utils import log_likelihood_heldout, bayesian_auc, pairwise_disagreement_error, top_k_accuracy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5de9193-7a3d-41d3-868c-8ec957ffb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = data_loader.lsat()\n",
    "cutoff = 25\n",
    "# A_lsat = data_loader.lsat()\n",
    "# A_ml_100k, ml_100k_ratings = data_loader.ml_100k(cutoff=cutoff)\n",
    "# A_hetrec_2k, hetrec_2k_ratings  = data_loader.hetrec_2k(cutoff=50)\n",
    "A_ml_1m, ml_1m_ratings = data_loader.ml_1m(cutoff=cutoff, top_k_cutoff=100)\n",
    "# A_bx, bx_ratings = data_loader.bx_book(cutoff=200)\n",
    "# A_genome, genome_ratings = data_loader.book_genome(cutoff=200)\n",
    "# A_ml_20m, ml_20m_ratings = data_loader.ml_20m(cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "597ed9e3-dc42-4c2a-a348-a2b7b45fe4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2934, 6040)\n",
      "2006\n"
     ]
    }
   ],
   "source": [
    "print(A_ml_1m.shape)\n",
    "print(len(ml_1m_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b823352-abae-454b-9e49-eda0d7248571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = A_ml_1m\n",
    "ratings = ml_1m_ratings\n",
    "sorted_ratings = sorted(ratings, key=lambda x: x[1], reverse=True)\n",
    "true_rank = [item for (item, _, _) in sorted_ratings] # Sort from most popular items\n",
    "\n",
    "# Ignore items that have \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9d0c96a-87c1-47af-a086-311cdf1beecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has shape (2934, 6040)\n",
      "mean num ratings in top 200: 864.76\n",
      "max num ratings in top 200: 3428\n",
      "median num ratings in top 200: 622.0\n",
      "min num ratings in top 200: 104\n"
     ]
    }
   ],
   "source": [
    "K = 200\n",
    "print(f\"Data has shape {A.shape}\")\n",
    "all_num_ratings = [num_ratings for (_, _, num_ratings) in sorted_ratings][:K]\n",
    "print(f\"mean num ratings in top {K}:\", np.mean(all_num_ratings))\n",
    "print(f\"max num ratings in top {K}:\", np.max(all_num_ratings))\n",
    "print(f\"median num ratings in top {K}:\", np.median(all_num_ratings))\n",
    "print(f\"min num ratings in top {K}:\", np.min(all_num_ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89ff59-604f-4d19-8c43-218d4258a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42e07f28-276c-4cc8-86f1-067c86e9824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_sub: 0.5\n",
      "Loglik: ASE=-0.6307220307281772, CMLE=0.0 MMLE=-0.6330921665207141, \n",
      "AUC: ASE=0.699238860310662, CMLE=0.0, MMLE=0.7013380704243893, \n",
      "Rank: ASE=0.0, CMLE=0.0, MMLE=0.0, \n",
      "Top-K: ASE=[0.7   0.72  0.68  0.8   0.802], MMLE=[0.5   0.52  0.52  0.715 0.768]\n",
      "Time: ASE=6.726557970046997, CMLE=0.0, MMLE=2.3011624813079834\n",
      "p_sub: 0.75\n",
      "Loglik: ASE=-0.6286397746971168, CMLE=0.0 MMLE=-0.6299505596007663, \n",
      "AUC: ASE=0.7006752322239423, CMLE=0.0, MMLE=0.7028008066056033, \n",
      "Rank: ASE=0.0, CMLE=0.0, MMLE=0.0, \n",
      "Top-K: ASE=[0.8   0.76  0.74  0.85  0.834], MMLE=[0.7   0.64  0.7   0.785 0.786]\n",
      "Time: ASE=8.024992942810059, CMLE=0.0, MMLE=2.7260897159576416\n"
     ]
    }
   ],
   "source": [
    "auc_ase = 0.\n",
    "auc_cmle = 0.\n",
    "auc_mmle = 0.\n",
    "loglik_ase = 0.\n",
    "loglik_cmle = 0.\n",
    "loglik_mmle = 0.\n",
    "pd_ase = 0.\n",
    "pd_cmle = 0.\n",
    "pd_mmle = 0.\n",
    "\n",
    "time_ase = 0.\n",
    "time_cmle = 0.\n",
    "time_mmle = 0.\n",
    "\n",
    "n_trials = 1\n",
    "seed = 119\n",
    "p_train = 0.8\n",
    "\n",
    "np.random.seed(seed)\n",
    "trial_seeds = np.random.randint(0, 9999, size=(n_trials,))\n",
    "sigma = 1\n",
    "K_array = [10, 25, 50, 200, 500]\n",
    "p_array = [0.5, 0.75]\n",
    "lambd_arr = [0.5, 1.]\n",
    "\n",
    "for j, p_sub in enumerate(p_array):\n",
    "    auc_ase = 0.\n",
    "    auc_cmle = 0.\n",
    "    auc_mmle = 0.\n",
    "    loglik_ase = 0.\n",
    "    loglik_cmle = 0.\n",
    "    loglik_mmle = 0.\n",
    "    pd_ase = 0.\n",
    "    pd_cmle = 0.\n",
    "    pd_mmle = 0.\n",
    "    top_K_ase = []\n",
    "    top_K_mmle = []\n",
    "\n",
    "    time_ase = 0.\n",
    "    time_cmle = 0.\n",
    "    time_mmle = 0.\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        # Partition data\n",
    "        all_train_data, test_data = eval_utils.partition_data(A, p_train=p_train, seed=trial_seeds[i])\n",
    "\n",
    "        # Extract a subset of the columns\n",
    "        train_data = all_train_data[:, :int(p_sub * all_train_data.shape[1])]\n",
    "\n",
    "        # Conditional MLE\n",
    "        # start = time.time()\n",
    "        # est_cmle = conditional_mle.rasch_conditional(data, return_beta=True)\n",
    "        # time_cmle += 1./n_trials * (time.time() - start)\n",
    "        # loglik_cmle += 1./n_trials * log_likelihood_heldout(est_cmle, test_data)\n",
    "        \n",
    "        # Marginal MLE\n",
    "        start = time.time()\n",
    "        est_mmle = rasch_mml.rasch_mml(train_data, return_beta=True) \n",
    "        time_mmle += 1./n_trials * (time.time() - start)\n",
    "        start = time.time()\n",
    "        loglik_mmle += 1./n_trials * log_likelihood_heldout(est_mmle, test_data)\n",
    "        auc_mmle += 1./n_trials * bayesian_auc(est_mmle, test_data, sigma)\n",
    "        est_rank_mmle = np.argsort(est_mmle)[::-1]\n",
    "        top_K_mmle += [[top_k_accuracy(true_rank, est_rank_mmle, k) for k in K_array]]\n",
    "\n",
    "\n",
    "        # Accelerated spectral method\n",
    "        start = time.time()\n",
    "        lambd = 1.\n",
    "        est_ase = spectral_estimate(train_data, lambd=lambd, regularization=\"uniform\") # Note regularization\n",
    "        time_ase += 1./n_trials * (time.time() - start)\n",
    "        loglik_ase += 1./n_trials * log_likelihood_heldout(est_ase, test_data, 2)\n",
    "        auc_ase += 1./n_trials * bayesian_auc(est_ase, test_data, sigma)\n",
    "        est_rank_ase = np.argsort(est_ase)[::-1]\n",
    "        top_K_ase += [[top_k_accuracy(true_rank, est_rank_ase, k) for k in K_array]]\n",
    "        \n",
    "    top_K_ase = np.array(top_K_ase)\n",
    "    top_K_mmle = np.array(top_K_mmle)\n",
    "\n",
    "    print(\n",
    "        f\"p_sub: {p_sub}\\n\" +\n",
    "        f\"Loglik: ASE={loglik_ase}, CMLE={loglik_cmle} MMLE={loglik_mmle}, \\n\" +\n",
    "        f\"AUC: ASE={auc_ase}, CMLE={auc_cmle}, MMLE={auc_mmle}, \\n\" +\n",
    "        f\"Rank: ASE={pd_ase}, CMLE={pd_cmle}, MMLE={pd_mmle}, \\n\" +\n",
    "        f\"Top-K: ASE={np.mean(top_K_ase, 0)}, MMLE={np.mean(top_K_mmle, 0)}\\n\" +\n",
    "        f\"Time: ASE={time_ase}, CMLE={time_cmle}, MMLE={time_mmle}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2297943-d78f-4970-9748-23d84ab8deaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4caaf10-a400-4676-9b73-e591b3489dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c63a6-9f47-4315-98d9-72453e472076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e5b95-f0ed-495f-ba40-40a563ffa99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d364b9-0944-403a-a39a-43278007e4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277f230-fc35-4cad-916a-fccfe7e2056a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
